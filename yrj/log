11.4搭建环境。

11.5了解监督学习和非监督学习。

11.6了解线性回归模型和代价函数。

11.7了解梯度下降和学习率。

11.8了解如何判断是否收敛。

11.11了解逻辑回归和决策边界。

11.12了解过拟合和解决过拟合的方法。

11.13了解神经元和神经网络。

11.14了解TensorFlow和前向传播。

11.15了解激活函数和多类。

11.18练习不同图片格式之间的转换。

11.19练习运用各种库。

11.20查看文献，初步完成了模型 MultiResUNet的加载和优化器设置。

11.21完成了初次训练，调试学习率调度器，检查了模型的收敛性和性能输出。

11.22修正了训练集和测试集划分逻辑，确保数据分布均衡，提升评估结果可信度。

11.25测试了模型在不同批量大小（batch size）下的训练效率和性能表现。

11.26分析了训练日志，发现Dice系数提升突出突出，调整了损失函数权重和学习率初始值。

11.27验证了模型的通用性，测试不同角度旋转数据对分割性能的影响。

11.28优化了图像增强流程，确保标签和输入图像的变换一致性，避免分割误差。

11.29开始对模型的测试集性能进行评估，记录了详细的Dice系数和IoU结果。

12.2最后发现dice还是不高，接手同事的UNet模型(dice:0.77)。

12.3对UNet模型进行优化，重点分析动态学习率和注意力机制。

12.4加入注意力机制SE-BLock。

12.5训练模型。

12.6加入动态学习率。

12.9评估了优化后的模型性能，对比了损失曲线和评估指标曲线的变化。

12.10引入将训练过程的数据导出excel表。

12.11UNet模型dice最后0.78。

12.12搭建新模型GRFB模型。

12.13引入新的注意力机制attention gate和CBAM。

12.16搭建新模型GRFB模型。

12.17查询更多优化的方法。

12.18优化代码。

12.19尝试不同的卷积次数。

12.20训练GRFB模型。

12.23GRFB模型dice最后0.79。

12.24再加入更多卷积就会超出内存。

12.25思路转为优化训练集图像。

12.26研究小波变换图像。

12.27理解原理。

12.30编写转换的代码。

12.31调试转换代码。

1.2引入批量转换。

1.3继续调试代码。

1.6用优化后的图像重新训练模型。

1.7查询更多模型。

1.9调试小波变换参数, 阈值过高的问题, 当前代码中的阈值 threshold=20 对图像进行软阈值化可能过于激进，导致细节（如血管）被认为是噪声而被抹除, 改成自适应阈值策略。

1.10调试小波变换参数, 尝试调整分解层数，尤其是对于高分辨率的图像，尝试 level=3。

1.13调试小波变换参数, 尝试硬阈值化 (mode='hard')，它仅移除低于阈值的系数，而保留较大的系数。

1.14调试小波变换参数, 当前使用的小波基 db1 不适合保留图像中的细小结构。
